# Chatbot Widget Usability Test Plan

This document outlines the approach for conducting usability testing of the chatbot widget UX.

## Objective:
- Evaluate the ease of use and user satisfaction with the chatbot widget.
- Identify any pain points, confusions, or areas for improvement in the user experience.
- Ensure the chatbot interactions are intuitive and helpful.

## Test Environment:
-   **Participants**: A diverse group of target users (e.g., students, researchers, general readers).
-   **Setting**: Controlled environment or remote moderated sessions.
-   **Tools**: Screen recording software, note-taking tools, post-test questionnaires.

## Test Scenarios/Tasks:

### 1. Initial Interaction:
-   **Task**: Locate and open the chatbot widget.
-   **Expected**: Button is easily discoverable; chat window opens without issues.

### 2. Asking a Book-Related Question:
-   **Task**: Ask a question about a specific topic within the textbook (e.g., "What is ROS 2?").
-   **Expected**:
    -   User can easily type and send a message.
    -   Bot response is clear, concise, and relevant.
    -   Citations are visible and clickable.

### 3. Asking a Course-Related Question:
-   **Task**: Switch to "Course" mode and ask a broader question (e.g., "What are common applications of humanoid robotics?").
-   **Expected**:
    -   User can easily switch modes.
    -   Bot response integrates information from both textbook and (simulated) course materials.

### 4. Asking from Selected Text:
-   **Task**: Select a paragraph of text on a page, activate the "Answer based on selected text" feature, and ask a question relevant to the selection.
-   **Expected**:
    -   Button appears on text selection.
    -   Chatbot opens and answers based solely on the selected text.

### 5. Multi-language Interaction:
-   **Task**: Change the chatbot language to Urdu/Arabic and ask a question.
-   **Expected**: Chatbot UI and responses are in the selected language.

## Metrics for Evaluation:
-   **Task Completion Rate**: Percentage of users successfully completing each task.
-   **Time on Task**: Time taken to complete each task.
-   **Error Rate**: Number of errors or missteps during task completion.
-   **Subjective Satisfaction**: User ratings from questionnaires (e.g., SUS score, Likert scale).
-   **Verbal Feedback**: Comments and suggestions from participants.

## Procedure:
1.  Onboard participants and explain the purpose of the test.
2.  Guide participants through a series of predefined tasks/scenarios.
3.  Observe user interactions, record screens, and take notes.
4.  Conduct post-test interviews and administer questionnaires.
5.  Analyze data to identify usability issues and recommendations.

## Acceptance Criteria:
-   80% task completion rate for critical tasks.
-   Average task time within acceptable limits.
-   SUS score of 68 or higher.
-   No critical usability issues identified.
