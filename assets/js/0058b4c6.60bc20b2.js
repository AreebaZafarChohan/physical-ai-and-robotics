"use strict";(self.webpackChunkphysical_ai_and_robotics=self.webpackChunkphysical_ai_and_robotics||[]).push([[849],{6164(i){i.exports=JSON.parse('{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"link","href":"/docs/intro","label":"Introduction","docId":"intro","unlisted":false},{"type":"category","label":"Module 1: The Robotic Nervous System (ROS 2)","items":[{"type":"link","href":"/docs/module-ros/intro-to-ros2","label":"Introduction to ROS 2","docId":"module-ros/intro-to-ros2","unlisted":false},{"type":"link","href":"/docs/module-ros/nodes-topics-services","label":"Nodes, Topics, and Services in ROS 2","docId":"module-ros/nodes-topics-services","unlisted":false},{"type":"link","href":"/docs/module-ros/rclpy-integration","label":"RCLPY Integration: Python Client Library for ROS 2","docId":"module-ros/rclpy-integration","unlisted":false},{"type":"link","href":"/docs/module-ros/urdf-for-humanoids","label":"URDF for Humanoids in ROS 2","docId":"module-ros/urdf-for-humanoids","unlisted":false},{"type":"category","label":"Module 1 Quizzes","items":[{"type":"link","href":"/docs/module-ros/quizzes/quiz-intro-to-ros2","label":"Quiz: \\"Introduction to ROS 2\\"","docId":"module-ros/quizzes/quiz-intro-to-ros2","unlisted":false},{"type":"link","href":"/docs/module-ros/quizzes/quiz-nodes-topics-services","label":"Quiz: \\"Nodes, Topics, and Services in ROS 2\\"","docId":"module-ros/quizzes/quiz-nodes-topics-services","unlisted":false},{"type":"link","href":"/docs/module-ros/quizzes/quiz-rclpy-integration","label":"Quiz: \\"RCLPY Integration\\"","docId":"module-ros/quizzes/quiz-rclpy-integration","unlisted":false},{"type":"link","href":"/docs/module-ros/quizzes/quiz-urdf-for-humanoids","label":"Quiz: \\"URDF for Humanoids\\"","docId":"module-ros/quizzes/quiz-urdf-for-humanoids","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 1 Try with AI","items":[{"type":"link","href":"/docs/module-ros/try-with-ai/ai-intro-to-ros2","label":"Try with AI: \\"Introduction to ROS 2\\"","docId":"module-ros/try-with-ai/ai-intro-to-ros2","unlisted":false},{"type":"link","href":"/docs/module-ros/try-with-ai/ai-nodes-topics-services","label":"Try with AI: \\"Nodes, Topics, and Services in ROS 2\\"","docId":"module-ros/try-with-ai/ai-nodes-topics-services","unlisted":false},{"type":"link","href":"/docs/module-ros/try-with-ai/ai-rclpy-integration","label":"Try with AI: \\"RCLPY Integration\\"","docId":"module-ros/try-with-ai/ai-rclpy-integration","unlisted":false},{"type":"link","href":"/docs/module-ros/try-with-ai/ai-urdf-for-humanoids","label":"Try with AI: \\"URDF for Humanoids\\"","docId":"module-ros/try-with-ai/ai-urdf-for-humanoids","unlisted":false}],"collapsed":true,"collapsible":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 2: The Digital Twin (Gazebo & Unity)","items":[{"type":"link","href":"/docs/module-digital-twin/gazebo-setup","label":"Gazebo Setup for Digital Twin","docId":"module-digital-twin/gazebo-setup","unlisted":false},{"type":"link","href":"/docs/module-digital-twin/physics-simulation","label":"Physics Simulation in Gazebo","docId":"module-digital-twin/physics-simulation","unlisted":false},{"type":"link","href":"/docs/module-digital-twin/sensor-simulation","label":"Sensor Simulation for Digital Twins","docId":"module-digital-twin/sensor-simulation","unlisted":false},{"type":"link","href":"/docs/module-digital-twin/unity-rendering","label":"Unity Rendering for Advanced Digital Twin Visualization","docId":"module-digital-twin/unity-rendering","unlisted":false},{"type":"category","label":"Module 2 Quizzes","items":[{"type":"link","href":"/docs/module-digital-twin/quizzes/quiz-gazebo-setup","label":"Quiz: \\"Gazebo Setup for Digital Twin\\"","docId":"module-digital-twin/quizzes/quiz-gazebo-setup","unlisted":false},{"type":"link","href":"/docs/module-digital-twin/quizzes/quiz-physics-simulation","label":"Quiz: \\"Physics Simulation in Gazebo\\"","docId":"module-digital-twin/quizzes/quiz-physics-simulation","unlisted":false},{"type":"link","href":"/docs/module-digital-twin/quizzes/quiz-sensor-simulation","label":"Quiz: \\"Sensor Simulation for Digital Twins\\"","docId":"module-digital-twin/quizzes/quiz-sensor-simulation","unlisted":false},{"type":"link","href":"/docs/module-digital-twin/quizzes/quiz-unity-rendering","label":"Quiz: \\"Unity Rendering\\"","docId":"module-digital-twin/quizzes/quiz-unity-rendering","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 2 Try with AI","items":[{"type":"link","href":"/docs/module-digital-twin/try-with-ai/ai-gazebo-setup","label":"Try with AI: \\"Gazebo Setup for Digital Twin\\"","docId":"module-digital-twin/try-with-ai/ai-gazebo-setup","unlisted":false},{"type":"link","href":"/docs/module-digital-twin/try-with-ai/ai-physics-simulation","label":"Try with AI: \\"Physics Simulation in Gazebo\\"","docId":"module-digital-twin/try-with-ai/ai-physics-simulation","unlisted":false},{"type":"link","href":"/docs/module-digital-twin/try-with-ai/ai-sensor-simulation","label":"Try with AI: \\"Sensor Simulation for Digital Twins\\"","docId":"module-digital-twin/try-with-ai/ai-sensor-simulation","unlisted":false},{"type":"link","href":"/docs/module-digital-twin/try-with-ai/ai-unity-rendering","label":"Try with AI: \\"Unity Rendering for Advanced Digital Twin Visualization\\"","docId":"module-digital-twin/try-with-ai/ai-unity-rendering","unlisted":false}],"collapsed":true,"collapsible":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 3: The AI-Robot Brain (NVIDIA Isaac)","items":[{"type":"link","href":"/docs/module-nvidia-isaac/isaac-sim-intro","label":"Introduction to NVIDIA Isaac Sim","docId":"module-nvidia-isaac/isaac-sim-intro","unlisted":false},{"type":"link","href":"/docs/module-nvidia-isaac/isaac-ros-vslam","label":"NVIDIA Isaac ROS: Visual SLAM (Vslam)","docId":"module-nvidia-isaac/isaac-ros-vslam","unlisted":false},{"type":"link","href":"/docs/module-nvidia-isaac/nav2-path-planning","label":"NVIDIA Isaac ROS: Nav2 Path Planning","docId":"module-nvidia-isaac/nav2-path-planning","unlisted":false},{"type":"link","href":"/docs/module-nvidia-isaac/reinforcement-learning","label":"Reinforcement Learning with NVIDIA Isaac Sim","docId":"module-nvidia-isaac/reinforcement-learning","unlisted":false},{"type":"category","label":"Module 3 Quizzes","items":[{"type":"link","href":"/docs/module-nvidia-isaac/quizzes/quiz-isaac-sim-intro","label":"Quiz: \\"Introduction to NVIDIA Isaac Sim\\"","docId":"module-nvidia-isaac/quizzes/quiz-isaac-sim-intro","unlisted":false},{"type":"link","href":"/docs/module-nvidia-isaac/quizzes/quiz-isaac-ros-vslam","label":"Quiz: \\"NVIDIA Isaac ROS - Visual SLAM (Vslam)\\"","docId":"module-nvidia-isaac/quizzes/quiz-isaac-ros-vslam","unlisted":false},{"type":"link","href":"/docs/module-nvidia-isaac/quizzes/quiz-nav2-path-planning","label":"Quiz: \\"NVIDIA Isaac ROS - Nav2 Path Planning\\"","docId":"module-nvidia-isaac/quizzes/quiz-nav2-path-planning","unlisted":false},{"type":"link","href":"/docs/module-nvidia-isaac/quizzes/quiz-reinforcement-learning","label":"Quiz: \\"Reinforcement Learning with NVIDIA Isaac Sim\\"","docId":"module-nvidia-isaac/quizzes/quiz-reinforcement-learning","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 3 Try with AI","items":[{"type":"link","href":"/docs/module-nvidia-isaac/try-with-ai/ai-isaac-sim-intro","label":"Try with AI: \\"Introduction to NVIDIA Isaac Sim\\"","docId":"module-nvidia-isaac/try-with-ai/ai-isaac-sim-intro","unlisted":false},{"type":"link","href":"/docs/module-nvidia-isaac/try-with-ai/ai-isaac-ros-vslam","label":"Try with AI: \\"NVIDIA Isaac ROS - Visual SLAM (Vslam)\\"","docId":"module-nvidia-isaac/try-with-ai/ai-isaac-ros-vslam","unlisted":false},{"type":"link","href":"/docs/module-nvidia-isaac/try-with-ai/ai-nav2-path-planning","label":"Try with AI: \\"NVIDIA Isaac ROS - Nav2 Path Planning\\"","docId":"module-nvidia-isaac/try-with-ai/ai-nav2-path-planning","unlisted":false},{"type":"link","href":"/docs/module-nvidia-isaac/try-with-ai/ai-reinforcement-learning","label":"Try with AI: \\"Reinforcement Learning with NVIDIA Isaac Sim\\"","docId":"module-nvidia-isaac/try-with-ai/ai-reinforcement-learning","unlisted":false}],"collapsed":true,"collapsible":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 4: Vision-Language-Action (VLA)","items":[{"type":"link","href":"/docs/module-vla/voice-to-action","label":"Voice-to-Action: Enabling Conversational Robotics","docId":"module-vla/voice-to-action","unlisted":false},{"type":"link","href":"/docs/module-vla/cognitive-planning-llms","label":"Cognitive Planning with Large Language Models (LLMs)","docId":"module-vla/cognitive-planning-llms","unlisted":false},{"type":"link","href":"/docs/module-vla/gpt-integration","label":"GPT Integration for Robot Control","docId":"module-vla/gpt-integration","unlisted":false},{"type":"category","label":"Module 4 Quizzes","items":[{"type":"link","href":"/docs/module-vla/quizzes/quiz-voice-to-action","label":"Quiz: \\"Voice-to-Action\\"","docId":"module-vla/quizzes/quiz-voice-to-action","unlisted":false},{"type":"link","href":"/docs/module-vla/quizzes/quiz-cognitive-planning-llms","label":"Quiz: \\"Cognitive Planning with LLMs\\"","docId":"module-vla/quizzes/quiz-cognitive-planning-llms","unlisted":false},{"type":"link","href":"/docs/module-vla/quizzes/quiz-gpt-integration","label":"Quiz: \\"GPT Integration for Robot Control\\"","docId":"module-vla/quizzes/quiz-gpt-integration","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Module 4 Try with AI","items":[{"type":"link","href":"/docs/module-vla/try-with-ai/ai-voice-to-action","label":"Try with AI: \\"Voice-to-Action\\"","docId":"module-vla/try-with-ai/ai-voice-to-action","unlisted":false},{"type":"link","href":"/docs/module-vla/try-with-ai/ai-cognitive-planning-llms","label":"Try with AI: \\"Cognitive Planning with Large Language Models (LLMs)\\"","docId":"module-vla/try-with-ai/ai-cognitive-planning-llms","unlisted":false},{"type":"link","href":"/docs/module-vla/try-with-ai/ai-gpt-integration","label":"Try with AI: \\"GPT Integration for Robot Control\\"","docId":"module-vla/try-with-ai/ai-gpt-integration","unlisted":false}],"collapsed":true,"collapsible":true}],"collapsed":true,"collapsible":true},{"type":"category","label":"Capstone Project","items":[{"type":"link","href":"/docs/capstone-project/autonomous-humanoid","label":"Capstone Project: Autonomous Humanoid Robot","docId":"capstone-project/autonomous-humanoid","unlisted":false},{"type":"category","label":"Capstone Project Quizzes","items":[{"type":"link","href":"/docs/capstone-project/quizzes/quiz-autonomous-humanoid","label":"Quiz: \\"Capstone Project - Autonomous Humanoid Robot\\"","docId":"capstone-project/quizzes/quiz-autonomous-humanoid","unlisted":false}],"collapsed":true,"collapsible":true},{"type":"category","label":"Capstone Project Try with AI","items":[{"type":"link","href":"/docs/capstone-project/try-with-ai/ai-autonomous-humanoid","label":"Try with AI: \\"Capstone Project - Autonomous Humanoid Robot\\"","docId":"capstone-project/try-with-ai/ai-autonomous-humanoid","unlisted":false}],"collapsed":true,"collapsible":true}],"collapsed":true,"collapsible":true}]},"docs":{"capstone-project/autonomous-humanoid":{"id":"capstone-project/autonomous-humanoid","title":"Capstone Project: Autonomous Humanoid Robot","description":"This capstone project serves as the culmination of your journey through the realms of Physical AI and Humanoid Robotics. Throughout this textbook, you\'ve acquired foundational knowledge in ROS 2, physics and sensor simulation with Gazebo and Unity, advanced AI for robotics with NVIDIA Isaac, and Vision-Language-Action (VLA) pipelines involving Large Language Models (LLMs). Now, it\'s time to integrate these diverse concepts into the ambitious goal of developing an autonomous humanoid robot.","sidebar":"tutorialSidebar"},"capstone-project/quizzes/quiz-autonomous-humanoid":{"id":"capstone-project/quizzes/quiz-autonomous-humanoid","title":"Quiz: \\"Capstone Project - Autonomous Humanoid Robot\\"","description":"Test your understanding of the challenges and integrated concepts in building an autonomous humanoid robot.","sidebar":"tutorialSidebar"},"capstone-project/try-with-ai/ai-autonomous-humanoid":{"id":"capstone-project/try-with-ai/ai-autonomous-humanoid","title":"Try with AI: \\"Capstone Project - Autonomous Humanoid Robot\\"","description":"This section provides curated prompts for you to explore the Capstone Project on Autonomous Humanoid Robots further with an AI assistant. Use these prompts with your favorite Large Language Model (LLM) to deepen your understanding or tackle complex system design challenges.","sidebar":"tutorialSidebar"},"component-usage":{"id":"component-usage","title":"Component Usage Guide","description":"This guide explains how to use the custom components available in the Physical AI & Humanoid Robotics platform."},"intro":{"id":"intro","title":"Introduction","description":"Welcome to the Physical AI & Humanoid Robotics platform. This documentation will guide you through the core concepts, implementation details, and applications of physical AI in humanoid robotics.","sidebar":"tutorialSidebar"},"module-digital-twin/gazebo-setup":{"id":"module-digital-twin/gazebo-setup","title":"Gazebo Setup for Digital Twin","description":"In the development of complex robotic systems, especially humanoids, a crucial step involves leveraging digital twins. A digital twin is a virtual representation of a physical object or system, allowing for testing, analysis, and optimization in a simulated environment before deployment in the real world. For robotics, Gazebo stands out as a powerful and widely used 3D physics simulator that provides a robust platform for creating and interacting with these digital twins.","sidebar":"tutorialSidebar"},"module-digital-twin/physics-simulation":{"id":"module-digital-twin/physics-simulation","title":"Physics Simulation in Gazebo","description":"Accurate physics simulation is the cornerstone of developing and testing robust robotic systems, particularly for complex humanoids in Physical AI. A high-fidelity physics simulator like Gazebo allows engineers and researchers to iterate rapidly, test algorithms in hazardous scenarios without risk to physical hardware, and gather vast amounts of data in controlled environments. This chapter explores how Gazebo handles physics simulation, delves into its configuration, and discusses best practices for achieving realistic and stable simulations.","sidebar":"tutorialSidebar"},"module-digital-twin/quizzes/quiz-gazebo-setup":{"id":"module-digital-twin/quizzes/quiz-gazebo-setup","title":"Quiz: \\"Gazebo Setup for Digital Twin\\"","description":"Test your understanding of Gazebo setup for creating digital twins in robotics.","sidebar":"tutorialSidebar"},"module-digital-twin/quizzes/quiz-physics-simulation":{"id":"module-digital-twin/quizzes/quiz-physics-simulation","title":"Quiz: \\"Physics Simulation in Gazebo\\"","description":"Test your knowledge on physics simulation within Gazebo for robotics.","sidebar":"tutorialSidebar"},"module-digital-twin/quizzes/quiz-sensor-simulation":{"id":"module-digital-twin/quizzes/quiz-sensor-simulation","title":"Quiz: \\"Sensor Simulation for Digital Twins\\"","description":"Test your knowledge on sensor simulation for robotic digital twins.","sidebar":"tutorialSidebar"},"module-digital-twin/quizzes/quiz-unity-rendering":{"id":"module-digital-twin/quizzes/quiz-unity-rendering","title":"Quiz: \\"Unity Rendering\\"","description":"Test your knowledge on leveraging Unity for advanced digital twin visualization.","sidebar":"tutorialSidebar"},"module-digital-twin/sensor-simulation":{"id":"module-digital-twin/sensor-simulation","title":"Sensor Simulation for Digital Twins","description":"For a robot\'s digital twin to be truly useful in the development and testing of Physical AI and humanoid robotics, it must accurately mimic not only the robot\'s physical dynamics but also its perception of the world. This is achieved through sensor simulation, a critical component of platforms like Gazebo. Realistic sensor data is paramount for developing robust control, navigation, and manipulation algorithms, as it directly impacts the robot\'s ability to understand and interact with its environment.","sidebar":"tutorialSidebar"},"module-digital-twin/try-with-ai/ai-gazebo-setup":{"id":"module-digital-twin/try-with-ai/ai-gazebo-setup","title":"Try with AI: \\"Gazebo Setup for Digital Twin\\"","description":"This section provides curated prompts for you to explore Gazebo setup for digital twins further with an AI assistant. Use these prompts with your favorite Large Language Model (LLM) to deepen your understanding or tackle simulation challenges.","sidebar":"tutorialSidebar"},"module-digital-twin/try-with-ai/ai-physics-simulation":{"id":"module-digital-twin/try-with-ai/ai-physics-simulation","title":"Try with AI: \\"Physics Simulation in Gazebo\\"","description":"This section provides curated prompts for you to explore physics simulation in Gazebo further with an AI assistant. Use these prompts with your favorite Large Language Model (LLM) to deepen your understanding or tackle simulation challenges.","sidebar":"tutorialSidebar"},"module-digital-twin/try-with-ai/ai-sensor-simulation":{"id":"module-digital-twin/try-with-ai/ai-sensor-simulation","title":"Try with AI: \\"Sensor Simulation for Digital Twins\\"","description":"This section provides curated prompts for you to explore sensor simulation in Gazebo further with an AI assistant. Use these prompts with your favorite Large Language Model (LLM) to deepen your understanding or tackle simulation challenges.","sidebar":"tutorialSidebar"},"module-digital-twin/try-with-ai/ai-unity-rendering":{"id":"module-digital-twin/try-with-ai/ai-unity-rendering","title":"Try with AI: \\"Unity Rendering for Advanced Digital Twin Visualization\\"","description":"This section provides curated prompts for you to explore Unity\'s role in advanced digital twin visualization further with an AI assistant. Use these prompts with your favorite Large Language Model (LLM) to deepen your understanding or tackle interactive development challenges.","sidebar":"tutorialSidebar"},"module-digital-twin/unity-rendering":{"id":"module-digital-twin/unity-rendering","title":"Unity Rendering for Advanced Digital Twin Visualization","description":"While Gazebo excels as a physics simulator for robotics, its visualization capabilities, though functional, may not always meet the demands for highly realistic and immersive digital twins, especially for humanoids. This is where a powerful real-time 3D development platform like Unity becomes invaluable. Unity can complement Gazebo by providing superior rendering, advanced UI tools, and extensive support for virtual reality (VR) and augmented reality (AR), elevating the digital twin experience.","sidebar":"tutorialSidebar"},"module-nvidia-isaac/isaac-ros-vslam":{"id":"module-nvidia-isaac/isaac-ros-vslam","title":"NVIDIA Isaac ROS: Visual SLAM (Vslam)","description":"Autonomous robots, especially humanoids navigating complex, unstructured environments, must continuously answer two fundamental questions: \\"Where am I?\\" and \\"What does my surroundings look like?\\". The process that concurrently addresses these questions is known as Simultaneous Localization and Mapping (SLAM). When SLAM relies primarily on visual information from cameras, it is termed Visual SLAM (Vslam). NVIDIA Isaac ROS provides highly optimized, GPU-accelerated modules for VSLAM, significantly boosting the perception capabilities of ROS 2-based robotic systems.","sidebar":"tutorialSidebar"},"module-nvidia-isaac/isaac-sim-intro":{"id":"module-nvidia-isaac/isaac-sim-intro","title":"Introduction to NVIDIA Isaac Sim","description":"As the field of Physical AI and humanoid robotics rapidly advances, the need for powerful, scalable, and high-fidelity simulation platforms becomes increasingly critical. NVIDIA, a leader in GPU computing and AI, has developed NVIDIA Isaac Sim as a robust solution specifically tailored for robotics development. Isaac Sim is built on NVIDIA\'s Omniverse platform, leveraging physically accurate simulation and rendering to accelerate the design, testing, and training of AI-driven robots in virtual environments.","sidebar":"tutorialSidebar"},"module-nvidia-isaac/nav2-path-planning":{"id":"module-nvidia-isaac/nav2-path-planning","title":"NVIDIA Isaac ROS: Nav2 Path Planning","description":"For any autonomous robot, the ability to navigate from a starting point to a goal while avoiding obstacles is fundamental. In the ROS 2 ecosystem, this critical capability is provided by the Navigation 2 (Nav2) stack. Nav2 is a complete software suite that enables mobile robots to autonomously navigate complex environments. When dealing with the demanding computational requirements of high-performance robotics, particularly for humanoids, NVIDIA Isaac ROS offers GPU-accelerated components that can significantly boost Nav2\'s efficiency and robustness.","sidebar":"tutorialSidebar"},"module-nvidia-isaac/quizzes/quiz-isaac-ros-vslam":{"id":"module-nvidia-isaac/quizzes/quiz-isaac-ros-vslam","title":"Quiz: \\"NVIDIA Isaac ROS - Visual SLAM (Vslam)\\"","description":"Test your knowledge on Visual SLAM and its acceleration with NVIDIA Isaac ROS.","sidebar":"tutorialSidebar"},"module-nvidia-isaac/quizzes/quiz-isaac-sim-intro":{"id":"module-nvidia-isaac/quizzes/quiz-isaac-sim-intro","title":"Quiz: \\"Introduction to NVIDIA Isaac Sim\\"","description":"Test your knowledge on the NVIDIA Isaac Sim robotics simulation platform.","sidebar":"tutorialSidebar"},"module-nvidia-isaac/quizzes/quiz-nav2-path-planning":{"id":"module-nvidia-isaac/quizzes/quiz-nav2-path-planning","title":"Quiz: \\"NVIDIA Isaac ROS - Nav2 Path Planning\\"","description":"Test your understanding of the ROS 2 Navigation Stack (Nav2) and its acceleration with NVIDIA Isaac ROS.","sidebar":"tutorialSidebar"},"module-nvidia-isaac/quizzes/quiz-reinforcement-learning":{"id":"module-nvidia-isaac/quizzes/quiz-reinforcement-learning","title":"Quiz: \\"Reinforcement Learning with NVIDIA Isaac Sim\\"","description":"Test your knowledge on Reinforcement Learning and its application with NVIDIA Isaac Sim.","sidebar":"tutorialSidebar"},"module-nvidia-isaac/reinforcement-learning":{"id":"module-nvidia-isaac/reinforcement-learning","title":"Reinforcement Learning with NVIDIA Isaac Sim","description":"Reinforcement Learning (RL) has emerged as a powerful paradigm for training robots to perform complex tasks by learning through trial and error. Instead of being explicitly programmed, an RL agent learns optimal behaviors by interacting with an environment, receiving rewards for desired actions and penalties for undesired ones. For Physical AI and humanoid robotics, where traditional programming can be exceedingly difficult for nuanced behaviors like balancing, walking, or dexterous manipulation, RL offers a promising path. However, training RL agents in the real world is often impractical, costly, and dangerous. This is where simulation environments, particularly NVIDIA Isaac Sim, become indispensable.","sidebar":"tutorialSidebar"},"module-nvidia-isaac/try-with-ai/ai-isaac-ros-vslam":{"id":"module-nvidia-isaac/try-with-ai/ai-isaac-ros-vslam","title":"Try with AI: \\"NVIDIA Isaac ROS - Visual SLAM (Vslam)\\"","description":"This section provides curated prompts for you to explore NVIDIA Isaac ROS VSLAM further with an AI assistant. Use these prompts with your favorite Large Language Model (LLM) to deepen your understanding or tackle system design challenges.","sidebar":"tutorialSidebar"},"module-nvidia-isaac/try-with-ai/ai-isaac-sim-intro":{"id":"module-nvidia-isaac/try-with-ai/ai-isaac-sim-intro","title":"Try with AI: \\"Introduction to NVIDIA Isaac Sim\\"","description":"This section provides curated prompts for you to explore NVIDIA Isaac Sim further with an AI assistant. Use these prompts with your favorite Large Language Model (LLM) to deepen your understanding or tackle simulation challenges.","sidebar":"tutorialSidebar"},"module-nvidia-isaac/try-with-ai/ai-nav2-path-planning":{"id":"module-nvidia-isaac/try-with-ai/ai-nav2-path-planning","title":"Try with AI: \\"NVIDIA Isaac ROS - Nav2 Path Planning\\"","description":"This section provides curated prompts for you to explore NVIDIA Isaac ROS Nav2 Path Planning further with an AI assistant. Use these prompts with your favorite Large Language Model (LLM) to deepen your understanding or tackle system design challenges.","sidebar":"tutorialSidebar"},"module-nvidia-isaac/try-with-ai/ai-reinforcement-learning":{"id":"module-nvidia-isaac/try-with-ai/ai-reinforcement-learning","title":"Try with AI: \\"Reinforcement Learning with NVIDIA Isaac Sim\\"","description":"This section provides curated prompts for you to explore Reinforcement Learning with NVIDIA Isaac Sim further with an AI assistant. Use these prompts with your favorite Large Language Model (LLM) to deepen your understanding or tackle RL design challenges.","sidebar":"tutorialSidebar"},"module-ros/intro-to-ros2":{"id":"module-ros/intro-to-ros2","title":"Introduction to ROS 2","description":"The Robotic Operating System (ROS) has been the de facto standard for robotic software development for over a decade. ROS 2 is the latest iteration, re-engineered to address the limitations of ROS 1 and to support the evolving demands of modern robotics, including real-time performance, multi-robot systems, and embedded platforms.","sidebar":"tutorialSidebar"},"module-ros/intro-to-ros2-personalized":{"id":"module-ros/intro-to-ros2-personalized","title":"Introduction to ROS 2 (Personalized)","description":"The Robotic Operating System (ROS) has been the de facto standard for robotic software development for over a decade. ROS 2 is the latest iteration, re-engineered to address the limitations of ROS 1 and to support the evolving demands of modern robotics, including real-time performance, multi-robot systems, and embedded platforms."},"module-ros/nodes-topics-services":{"id":"module-ros/nodes-topics-services","title":"Nodes, Topics, and Services in ROS 2","description":"In the world of the Robotic Operating System 2 (ROS 2), the ability of different software components to communicate seamlessly is fundamental to building complex and robust robotic systems. This communication paradigm is primarily facilitated through the concepts of Nodes, Topics, and Services. These elements form the backbone of ROS 2\'s distributed architecture, allowing for modularity, reusability, and scalability in robotic software development.","sidebar":"tutorialSidebar"},"module-ros/quizzes/quiz-intro-to-ros2":{"id":"module-ros/quizzes/quiz-intro-to-ros2","title":"Quiz: \\"Introduction to ROS 2\\"","description":"Test your knowledge on the fundamentals of ROS 2.","sidebar":"tutorialSidebar"},"module-ros/quizzes/quiz-nodes-topics-services":{"id":"module-ros/quizzes/quiz-nodes-topics-services","title":"Quiz: \\"Nodes, Topics, and Services in ROS 2\\"","description":"Test your understanding of the core communication primitives in ROS 2.","sidebar":"tutorialSidebar"},"module-ros/quizzes/quiz-rclpy-integration":{"id":"module-ros/quizzes/quiz-rclpy-integration","title":"Quiz: \\"RCLPY Integration\\"","description":"Test your knowledge on using RCLPY for ROS 2 development in Python.","sidebar":"tutorialSidebar"},"module-ros/quizzes/quiz-urdf-for-humanoids":{"id":"module-ros/quizzes/quiz-urdf-for-humanoids","title":"Quiz: \\"URDF for Humanoids\\"","description":"Test your understanding of URDF and its application to humanoid robots in ROS 2.","sidebar":"tutorialSidebar"},"module-ros/rclpy-integration":{"id":"module-ros/rclpy-integration","title":"RCLPY Integration: Python Client Library for ROS 2","description":"When developing robotic applications with ROS 2, Python is a popular choice due to its readability, vast ecosystem of libraries for AI and data science, and rapid prototyping capabilities. RCLPY is the official Python client library for ROS 2, providing a clean and intuitive interface to interact with the core ROS 2 concepts like nodes, topics, services, and actions. This chapter will delve into how to effectively use RCLPY to build robust ROS 2 applications in Python.","sidebar":"tutorialSidebar"},"module-ros/try-with-ai/ai-intro-to-ros2":{"id":"module-ros/try-with-ai/ai-intro-to-ros2","title":"Try with AI: \\"Introduction to ROS 2\\"","description":"This section provides curated prompts for you to explore the concepts of ROS 2 further with an AI assistant. Use these prompts with your favorite Large Language Model (LLM) to deepen your understanding or tackle coding challenges.","sidebar":"tutorialSidebar"},"module-ros/try-with-ai/ai-nodes-topics-services":{"id":"module-ros/try-with-ai/ai-nodes-topics-services","title":"Try with AI: \\"Nodes, Topics, and Services in ROS 2\\"","description":"This section provides curated prompts for you to further explore the concepts of ROS 2 nodes, topics, and services with an AI assistant. Use these prompts with your favorite Large Language Model (LLM) to deepen your understanding or tackle system design challenges.","sidebar":"tutorialSidebar"},"module-ros/try-with-ai/ai-rclpy-integration":{"id":"module-ros/try-with-ai/ai-rclpy-integration","title":"Try with AI: \\"RCLPY Integration\\"","description":"This section provides curated prompts for you to explore RCLPY integration further with an AI assistant. Use these prompts with your favorite Large Language Model (LLM) to deepen your understanding or tackle coding challenges.","sidebar":"tutorialSidebar"},"module-ros/try-with-ai/ai-urdf-for-humanoids":{"id":"module-ros/try-with-ai/ai-urdf-for-humanoids","title":"Try with AI: \\"URDF for Humanoids\\"","description":"This section provides curated prompts for you to explore URDF and its application to humanoid robots further with an AI assistant. Use these prompts with your favorite Large Language Model (LLM) to deepen your understanding or tackle modeling challenges.","sidebar":"tutorialSidebar"},"module-ros/urdf-for-humanoids":{"id":"module-ros/urdf-for-humanoids","title":"URDF for Humanoids in ROS 2","description":"When working with complex robots, especially humanoids, accurately describing their physical structure is paramount. This is where URDF (Unified Robot Description Format) comes into play. URDF is an XML-based file format used in ROS 2 (and ROS 1) to describe all aspects of a robot, including its kinematic structure, visual appearance, collision properties, and inertial characteristics. For humanoid robots, URDF allows for the meticulous definition of their numerous links and joints, which is crucial for simulation, motion planning, and control.","sidebar":"tutorialSidebar"},"module-vla/cognitive-planning-llms":{"id":"module-vla/cognitive-planning-llms","title":"Cognitive Planning with Large Language Models (LLMs)","description":"Traditional robotics has largely relied on meticulously engineered, rule-based systems for task and motion planning. While effective for well-defined problems in structured environments, these methods struggle with ambiguity, novelty, and the ability to generalize across diverse situations. In the quest for truly intelligent Physical AI and humanoid robots, the ability to perform cognitive planning\u2014reasoning about high-level goals, decomposing them into sub-tasks, and adapting strategies dynamically\u2014is paramount. Recent advancements in Large Language Models (LLMs) have opened exciting new avenues for endowing robots with these cognitive capabilities.","sidebar":"tutorialSidebar"},"module-vla/gpt-integration":{"id":"module-vla/gpt-integration","title":"GPT Integration for Robot Control","description":"The emergence of powerful Large Language Models (LLMs) like OpenAI\'s GPT series has opened up unprecedented possibilities for enhancing robot intelligence and human-robot interaction. Integrating GPT into a robot\'s control architecture allows robots to understand high-level, ambiguous natural language commands, reason about tasks, and even generate complex action sequences. This chapter delves into the practical aspects of integrating GPT-like models into Physical AI and humanoid robotics, covering prompt engineering, communication, and addressing key challenges.","sidebar":"tutorialSidebar"},"module-vla/quizzes/quiz-cognitive-planning-llms":{"id":"module-vla/quizzes/quiz-cognitive-planning-llms","title":"Quiz: \\"Cognitive Planning with LLMs\\"","description":"Test your understanding of cognitive planning and the role of Large Language Models (LLMs) in robotics.","sidebar":"tutorialSidebar"},"module-vla/quizzes/quiz-gpt-integration":{"id":"module-vla/quizzes/quiz-gpt-integration","title":"Quiz: \\"GPT Integration for Robot Control\\"","description":"Test your knowledge on integrating GPT-like models into robot control systems.","sidebar":"tutorialSidebar"},"module-vla/quizzes/quiz-voice-to-action":{"id":"module-vla/quizzes/quiz-voice-to-action","title":"Quiz: \\"Voice-to-Action\\"","description":"Test your understanding of the Voice-to-Action pipeline in robotics.","sidebar":"tutorialSidebar"},"module-vla/try-with-ai/ai-cognitive-planning-llms":{"id":"module-vla/try-with-ai/ai-cognitive-planning-llms","title":"Try with AI: \\"Cognitive Planning with Large Language Models (LLMs)\\"","description":"This section provides curated prompts for you to explore Cognitive Planning with LLMs further with an AI assistant. Use these prompts with your favorite Large Language Model (LLM) to deepen your understanding or tackle planning challenges.","sidebar":"tutorialSidebar"},"module-vla/try-with-ai/ai-gpt-integration":{"id":"module-vla/try-with-ai/ai-gpt-integration","title":"Try with AI: \\"GPT Integration for Robot Control\\"","description":"This section provides curated prompts for you to explore GPT Integration for Robot Control further with an AI assistant. Use these prompts with your favorite Large Language Model (LLM) to deepen your understanding or tackle system integration challenges.","sidebar":"tutorialSidebar"},"module-vla/try-with-ai/ai-voice-to-action":{"id":"module-vla/try-with-ai/ai-voice-to-action","title":"Try with AI: \\"Voice-to-Action\\"","description":"This section provides curated prompts for you to explore Voice-to-Action in robotics further with an AI assistant. Use these prompts with your favorite Large Language Model (LLM) to deepen your understanding or tackle system design challenges.","sidebar":"tutorialSidebar"},"module-vla/voice-to-action":{"id":"module-vla/voice-to-action","title":"Voice-to-Action: Enabling Conversational Robotics","description":"The ability for humans to intuitively communicate with robots using natural language, particularly voice, represents a profound step towards seamless human-robot interaction. Voice-to-Action refers to the entire pipeline that allows a robot to perceive spoken commands, understand their intent, and translate that understanding into meaningful physical actions in the real world. For Physical AI and humanoid robotics, achieving robust Voice-to-Action capabilities is crucial for enabling more natural, accessible, and versatile applications, moving beyond teleoperation or predefined task sequences.","sidebar":"tutorialSidebar"}}}}')}}]);